"""Initial migration with all existing models and account lockout

Revision ID: c25e20b7535f
Revises: 
Create Date: 2025-10-25 15:21:46.166993

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'c25e20b7535f'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('scans')
    op.drop_table('statistics_cache')
    with op.batch_alter_table('scan_log', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_scan_log_timestamp'))

    op.drop_table('scan_log')
    op.drop_table('bags')
    op.drop_table('schema_migrations')
    with op.batch_alter_table('audit_log', schema=None) as batch_op:
        batch_op.create_index('idx_audit_action_timestamp', ['action', 'timestamp'], unique=False)
        batch_op.create_index('idx_audit_user_timestamp', ['user_id', 'timestamp'], unique=False)

    with op.batch_alter_table('bag', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_bag_qr_type'))
        batch_op.drop_index(batch_op.f('idx_bag_qr_upper'))

    with op.batch_alter_table('bill_bag', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_bill_bag_bag'))
        batch_op.drop_index(batch_op.f('idx_bill_bag_bill'))

    with op.batch_alter_table('link', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_link_child'))
        batch_op.drop_index(batch_op.f('idx_link_parent'))

    with op.batch_alter_table('scan', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_scan_child'))
        batch_op.drop_index(batch_op.f('idx_scan_parent'))
        batch_op.create_index('idx_scan_timestamp_user', ['timestamp', 'user_id'], unique=False)
        batch_op.create_index('idx_scan_user_timestamp', ['user_id', 'timestamp'], unique=False)

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('scan', schema=None) as batch_op:
        batch_op.drop_index('idx_scan_user_timestamp')
        batch_op.drop_index('idx_scan_timestamp_user')
        batch_op.create_index(batch_op.f('idx_scan_parent'), ['parent_bag_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_scan_child'), ['child_bag_id'], unique=False)

    with op.batch_alter_table('link', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_link_parent'), ['parent_bag_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_link_child'), ['child_bag_id'], unique=False)

    with op.batch_alter_table('bill_bag', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('idx_bill_bag_bill'), ['bill_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_bill_bag_bag'), ['bag_id'], unique=False)

    # Create expression-based indexes using raw SQL (these use PostgreSQL functions)
    op.execute('CREATE INDEX IF NOT EXISTS idx_bag_qr_upper ON bag (UPPER(qr_id::text))')
    op.execute('CREATE INDEX IF NOT EXISTS idx_bag_qr_type ON bag (UPPER(qr_id::text), type)')

    with op.batch_alter_table('audit_log', schema=None) as batch_op:
        batch_op.drop_index('idx_audit_user_timestamp')
        batch_op.drop_index('idx_audit_action_timestamp')

    op.create_table('schema_migrations',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('migration_name', sa.VARCHAR(length=255), autoincrement=False, nullable=False),
    sa.Column('executed_at', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.Column('success', sa.BOOLEAN(), server_default=sa.text('true'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('schema_migrations_pkey')),
    sa.UniqueConstraint('migration_name', name=op.f('schema_migrations_migration_name_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    op.create_table('bags',
    sa.Column('id', sa.INTEGER(), server_default=sa.text("nextval('bags_id_seq'::regclass)"), autoincrement=True, nullable=False),
    sa.Column('qr_code', sa.VARCHAR(length=100), autoincrement=False, nullable=False),
    sa.Column('customer_name', sa.VARCHAR(length=200), autoincrement=False, nullable=True),
    sa.Column('weight', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('status', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('parent_bag_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('is_parent', sa.BOOLEAN(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['parent_bag_id'], ['bags.id'], name='bags_parent_bag_id_fkey'),
    sa.PrimaryKeyConstraint('id', name='bags_pkey'),
    sa.UniqueConstraint('qr_code', name='bags_qr_code_key', postgresql_include=[], postgresql_nulls_not_distinct=False),
    postgresql_ignore_search_path=False
    )
    op.create_table('scan_log',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('bag_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('action', sa.VARCHAR(length=50), autoincrement=False, nullable=False),
    sa.Column('timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('response_time_ms', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['bag_id'], ['bag.id'], name=op.f('scan_log_bag_id_fkey')),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], name=op.f('scan_log_user_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('scan_log_pkey'))
    )
    with op.batch_alter_table('scan_log', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_scan_log_timestamp'), ['timestamp'], unique=False)

    op.create_table('statistics_cache',
    sa.Column('id', sa.INTEGER(), server_default=sa.text('1'), autoincrement=False, nullable=False),
    sa.Column('total_bags', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('parent_bags', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('child_bags', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('total_scans', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('total_bills', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('total_users', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=True),
    sa.Column('last_updated', postgresql.TIMESTAMP(), server_default=sa.text('CURRENT_TIMESTAMP'), autoincrement=False, nullable=True),
    sa.CheckConstraint('id = 1', name=op.f('single_row')),
    sa.PrimaryKeyConstraint('id', name=op.f('statistics_cache_pkey'))
    )
    op.create_table('scans',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('bag_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('scan_type', sa.VARCHAR(length=50), autoincrement=False, nullable=True),
    sa.Column('timestamp', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['bag_id'], ['bags.id'], name=op.f('scans_bag_id_fkey')),
    sa.ForeignKeyConstraint(['user_id'], ['user.id'], name=op.f('scans_user_id_fkey')),
    sa.PrimaryKeyConstraint('id', name=op.f('scans_pkey'))
    )
    # ### end Alembic commands ###
